# Here we still have all of the same DSUI events from the Sigpipe DSUI example.
# However, we have added in the DSKI context switch events. 
# We continue to do the same thing with the DSUI events, but using both these
# and the DSKI events, we can extract more information from the data stream.
# You can see we have to filter the DSKI context switches by PID because
# it logs every single context switch that occurs on the machine, rather than
# just those specific to sigpipe. You can see that the amount of useless information
# in the unfiltered pipeline is astonishing. 

# In the next example with Active Filtering, we will be able to reject all events
# which are not generated by threads in the sigpipe example itself.

<main>
filter_modules = ["sigpipe_dsui_filter.py", "custom_PIDs"]
filters = {
	dsui = [
		head.input(
			file = ["sigpipe.dsui.bin"]
			namespace = {
				GAP_INTERVALS = {
					entities = {
						GAP_ONE = interval(
							desc = "gap one intervals"
						)
						ALL_GAPS = interval(
							desc = "all gaps intervals"
						)
					}
				}
				GAP_HISTOS = {
					entities = {
						GAP_ONE_HISTO = histogram(
							desc = "gap one histogram"
							units = "ns" 
						)
						ALL_GAPS_HISTO = histogram(
							desc = "all gaps histogram"
							units = "ns" 
						)
					}
				}
				PIPE_INTERVAL = {
					entities = {
						PIPE = interval(
							desc = "time for a signal to clear the whole pipeline"
						)
					}
				}
				PIPE_HISTO = {
					entities = {
						PIPE_HISTO = histogram(
							desc = "pipe traversal histogram"
							units = "ns" 
						)
					}
				}
			}
		)

		utility.timestamp()
		
		#This additional custom filter module has two filters
		#The filter_PID retrieves all the thread ID numbers and stores
		#them to a file, PIDlist
		custom_PIDs.filter_PID(
		    filename = "PIDlist"
		)
		
		#The split_outputs module in utility2 is designed to enable, as the name
		#implies, the splitting of output. This sends the whole datastream to 
		#all of the designated output pipelines. 
		utility2.split_outputs(
		    outputs = ["count_uf", "count_f", "custom"]
		)
		    
	]
	
	#These are the DSKI context switch events. We will use this filter to 
	#access the unfiltered context switch events--that is, all context switch
	#events that occur, including those not created by the sigpipe example.
	dski = [
		head.input(
			file = ["sigpipe1.dski.bin/chan/cpu*.bin"]
			namespace = {
				CPU_TIME_UF = {
					entities = {
						TIME_INTERVAL = interval(
							desc = "cpu time intervals"
						)
					}
				}
			}
		)

		utility.timestamp()
		
		utility2.split_outputs(
		    outputs = ["count_uf", "unfiltered_cpu_time", "pids"]
		)
		
	]
	
	#These are the same DSKI events, but will be filtered by PID to only access
	#those created by the sigpipe example.
	dski_filter = [
		head.input(
			file = ["sigpipe1.dski.bin/chan/cpu*.bin"]
			namespace = {
				CPU_TIME_F = {
					entities = {
						TIME_INTERVAL = interval(
							desc = "cpu time intervals"
						)
					}
				}
			}
		)

		utility.timestamp()
	    
	    utility2.split_outputs(
		    outputs = ["count_f"]
		)

	]
	
	#This is the same filter as in sigpipe DSUI
	custom = [
		head.input(
			conn = [dsui]
		)

		sigpipe_dsui_filter.pipeline_intervals(
			gap_one_interval = "GAP_INTERVALS/GAP_ONE"
			all_gaps_intervals = "GAP_INTERVALS/ALL_GAPS"
			pipeline_interval = "PIPE_INTERVAL/PIPE"
			consume = true
		)
		
		utility2.split_outputs(
		    outputs = ["create_histograms", "pids"]
		)
		
	]
	
	#This is the same filter as in sigpipe DSUI
	create_histograms = [
		head.input(
			conn = [custom]
		)

		conversion.interval_to_histogram(
			interval = "GAP_INTERVALS/GAP_ONE"
			histogram = "GAP_HISTOS/GAP_ONE_HISTO"
			buckets = 25
		)

		conversion.interval_to_histogram(
			interval = "GAP_INTERVALS/ALL_GAPS"
			histogram = "GAP_HISTOS/ALL_GAPS_HISTO"
			buckets = 25
		)

		conversion.interval_to_histogram(
			interval = "PIPE_INTERVAL/PIPE"
			histogram = "PIPE_HISTO/PIPE_HISTO"
			buckets = 50
		)
	]
	
	#This is the same filter as in sigpipe DSUI
	create_graphs = [
		head.input(
			conn = [create_histograms]
		)

		graph.histogram(
			histogram = "GAP_HISTOS/GAP_ONE_HISTO"
			title = "gap one histogram"
		)

		graph.histogram(
			histogram = "GAP_HISTOS/ALL_GAPS_HISTO"
			title = "all gaps histogram"
		)

		graph.histogram(
			histogram = "PIPE_HISTO/PIPE_HISTO"
			title = "total pipeline traversal time"
		)

	]
	
	#In this filter, we can see how much the computer is doing. Even on an essentially 
	#idle system, the machine will be doing other things. This gets every context switch
	#NOT spawned by the sigpipe example, logs them to a file, and counts them. 
	#You can make this even more interesting by running a kernel compile while running 
	#the sigpipe example. 
	pids = [
	    head.input(
	        conn = [custom, dski]
	    )
		
	    #We want to see all context switch events that occur during a single gap.
	    #This may be a surprising amount. To one not familiar with the speed of 
	    #computers, they may think that the computer does nothing while a 
	    #signal is sent from one thread to another. This is not the case.
	    utility2.filter_by_interval(
	        interval = "GAP_INTERVALS/GAP_ONE"
	    )
	    
	    #Then discard all context switch events (as well as all DSUI events) that
	    #are generated by sigpipe.
	    custom_PIDs.filter_context_events(
	        filename = "PIDlist"
	        discard = true
	    )
	    
	    #Narrate the resulting context switch events to a file
	    utility2.narrate(
	        output = "gap_events"
	    )
	    
	    #Count the number of context switch events in the gap between the threads 2 and 3.
	    utility2.count()
	    
	]


    #Count the total number of events in the unfiltered datastream
	count_uf = [
		head.input(
			conn = [dsui, dski]
		)

		utility2.count()
		
	]
	
	#Here we count the number of events in the filtered datastream 
	#This should be much lower.
	count_f = [
	    head.input(
	        conn = [dsui, dski_filter]
	    )
	    
	    #Once we know the thread ID numbers, we can filter the
		#context switch events. We remove all context
		#switch events from the data stream which do not have matching
		#PIDs. 
		custom_PIDs.filter_context_events(
		    filename = "PIDlist"
	    )
	    
	    utility2.count()
	]

    #This is a graph of the total CPU time of all the running tasks. 
    #The custom filter calculates this by summing the context switch 
    #events which we enabled in the sigpipe1.dski configuration file. 
    #However, this does calculate it for ALL tasks. In the next pipeline,
    #the histogram will be composed of only context switches to and from
    #the sigpipe example itself.
	unfiltered_cpu_time = [
		head.input(
			conn = [dski]
		)

		conversion2.dski_event_to_interval(
            start_event = "SCHEDULER/SWITCH_FROM"
            end_event = "SCHEDULER/SWITCH_TO"
            interval = "CPU_TIME_UF/TIME_INTERVAL"
            consume = true
            ignore_missing = true
        )

		graph.interval_histogram(
			interval = "CPU_TIME_UF/TIME_INTERVAL"
			title = "CPU time for unfiltered data"
			filename = "CPU_TIME_UF.ps"
			xaxis_label = "Time interval spent on CPU (us)"
			yaxis_log = true
			divisor = 1000
			buckets = 30
		)
	]
	
	#This is again a histogram of the CPU time. However, with the filtered 
	#datastream, the sheer volume of events will be much lower. The distribution
	#will also be significantly changed.
	filtered_cpu_time = [
		head.input(
			conn = [count_f]
		)

        conversion2.dski_event_to_interval(
            start_event = "SCHEDULER/SWITCH_FROM"
            end_event = "SCHEDULER/SWITCH_TO"
            interval = "CPU_TIME_F/TIME_INTERVAL"
            consume = true
            ignore_missing = true
        )

		graph.interval_histogram(
			interval = "CPU_TIME_F/TIME_INTERVAL"
			title = "CPU time for filtered data"
			filename = "CPU_TIME_F.ps"
			xaxis_label = "Time interval spent on CPU (us)"
			yaxis_log = true
			divisor = 1000
			buckets = 30
		)
	]
}





